<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="FILM creates slow motion footage from two near duplicate photos.">
  <meta name="keywords" content="frame-interpolation, optical-flow, warping, forward-warp, splatting">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AMT: All-Pairs Multi-Field Transforms for Efficient Frame Interpolation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');



  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <script src="https://kit.fontawesome.com/1364dea754.js" crossorigin="anonymous"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">AMT: All-Pairs Multi-Field Transforms for Efficient Frame Interpolation</h1>
          <div class="is-size-4 publication-authors">
            <span class="author-block">
             <a href="https://paper99.github.io">Zhen Li</a><sup>1*</sup>,
            </span>
            <span class="author-block">
                <a href="https://scholar.google.com/citations?user=fM1vXiYAAAAJ&hl=en">Zuo-Liang Zhu</a><sup>1*</sup>,
            </span>
            <span class="author-block">
                <a href="https://scholar.google.com/citations?user=fM1vXiYAAAAJ&hl=en">Ling-Hao Han</a><sup>1</sup>,
            </span>
            <span class="author-block">
                <a href="https://scholar.google.com/citations?user=fF8OFV8AAAAJ&hl=en">Qibin Hou</a><sup>1</sup>,
            </span>
            <br>
            <span class="author-block">
                <a href="https://scholar.google.com/citations?user=RZLYwR0AAAAJ&hl=en">Chun-Le Guo</a><sup>1#</sup>,
            </span>
            <span class="author-block">
                <a href="https://https://mmcheng.net">Ming-Ming Cheng</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>VCIP, CS, Nankai University &nbsp; &nbsp;</span>
            <span class="author-block"><sup>*</sup>Equally Contribution &nbsp; &nbsp;</span>
            <span class="author-block"><sup>#</sup>Corresponding Auther &nbsp; &nbsp;</span>
          </div>
          <h1 style="font-size:24px;font-weight:bold">CVPR 2023</h1>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2202.04901"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2202.04901"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://ai.googleblog.com/2022/10/large-motion-frame-interpolation.html"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <img src="https://upload.wikimedia.org/wikipedia/commons/d/d0/Google_Colaboratory_SVG_Logo.svg">
                  </span>
                  <span>Colab</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video(TBD)</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/MCG-NKU/AMT"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/spaces/NKU-AMT/AMT"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <img src="static/assets/huggingface.svg">
                  </span>
                  <span>Hugging Face</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop height="100%">
        <source src="static/images/moment.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">FILM</span> turns near-duplicate photos into a slow motion footage that look like shot with a video camera.
      </h2>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop height="100%">
            <source src="static/images/000661/interpolated-2s.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop height="100%">
            <source src="static/images/000357/interpolated-2s.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop height="100%">
            <source src="static/images/000628/interpolated-2s.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop height="100%">
            <source src="static/images/000204/interpolated-2s.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop height="100%">
            <source src="static/images/000194/interpolated-2s.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop height="100%">
            <source src="static/images/000275/interpolated-2s.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop height="100%">
            <source src="static/images/000027/interpolated-2s.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop height="100%">
            <source src="static/images/000032/interpolated-2s.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop height="100%">
            <source src="static/images/000654/interpolated-2s.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container">

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            <font size="5">
            We present <strong>A</strong>ll-Pairs <strong>M</strong>ulti-Field <strong>T</strong>ransforms (AMT), a new network architecture for video frame interpolation. 
            It is based on two essential designs. 
            First, we build bidirectional correlation volumes for all pairs of pixels, and use the predicted bilateral flows to 
            retrieve correlations for updating both flows and the interpolated content feature. 
            Second, we derive multiple groups of fine-grained flow fields from one pair of updated coarse flows for performing 
            backward warping on the input frames separately. 
            Combining these two designs enables us to generate promising task-oriented flows and reduce the difficulties in 
            modeling large motions and handling occluded areas during frame interpolation. 
            These qualities promote our model to achieve state-of-the-art performance on various benchmarks with high efficiency. 
            Moreover, our convolution-based model competes favorably compared to Transformer-based models in terms of accuracy and efficiency. 
            </font>
          </p>
        </div>
      </div>
    </div>
  </div>
  <!--/ Abstract. -->


<section class="section">
  <div class="container">
    <div align="center" style="margin-top:20px;" style="margin-bottom:120px;">
      <h2 class="title is-3">Architecture Overview</h2>
      <img style='height: auto; width: 80%; object-fit: contain' src="static/assets/overview.png" alt="overview_image">
    </div> 
  </div>
</section>

<section class="section">
  <div class="container">
  <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/VRJSfc02dzU"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container content">
    <div align="center" style="margin-top:20px;" style="margin-bottom:120px;">
        <h2 class="title is-3">Appendix</h2>
    </div>
    <h3 class="title">BibTeX</h3>
    <pre><code>
        @inproceedings{licvpr23amt,
            title={AMT: All-Pairs Multi-Field Transforms for Efficient Frame Interpolation},
            author={Li, Zhen and Zhu, Zuo-Liang and Han, Ling-Hao and Hou, Qibin and Guo, Chun-Le and Cheng, Ming-Ming},
            booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
            year={2023}
         }
    </code></pre>
    <h3 class="title">Contact</h3>
    <p class="section-content-text">
        For technical questions, please contact <strong>zhenli1031[AT]gmail.com</strong> and <strong>nkuzhuzl[AT]gmail.com</strong>.
        For commercial licensing, please contact <strong>cmm[AT]nankai.edu.cn</strong>.
    </p>
    <h3 class="title">License</h3>
    <p class="section-content-text">
        This code is licensed under the <a href="https://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International</a> 
        for non-commercial use only. 
        Please note that any commercial use of this code requires formal permission prior to use.
    </p>
    <h3 class="title">Acknowledgements</h3>
    <p class="section-content-text">
        This work is funded by the National Key Research and Development Program of China (NO.2018AAA0100400), 
        Fundamental Research Funds for the Central Universities (Nankai University, NO.63223050), 
        China Postdoctoral Science Foundation (NO.2021M701780).
    </p>
  </div>

</section>
    

</body>
</html>
